{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18f9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f51fd328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.Uknown',\n",
       " 'Azizi N',\n",
       " 'Bhara M',\n",
       " 'Cristiano Ronaldo',\n",
       " 'Lionel Messi',\n",
       " 'Tony_Blair']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "dataset_folder ='Datasets10/face_inputs/'\n",
    "dir = os.listdir(dataset_folder)\n",
    "labels = []\n",
    "for item in dir:\n",
    "    if os.path.isdir(dataset_folder+item) == True:\n",
    "        labels.append(item)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67bb46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_batch_face.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346ab0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 109, 109, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 52, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 705,638\n",
      "Trainable params: 704,486\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1304885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x25bb4d00520>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x25bb4d472e0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25bb4d474f0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb4d2c820>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25bb4d314c0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x25bb4d00d30>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25bb4f5fd60>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb4f65430>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25bb4f6e2e0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x25bb4f6e460>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25bb4fb3e80>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb4fd6af0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25bb4fc2430>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x25bb4f8dd00>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25bb5009ac0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb4fe4d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25bb5012190>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x25bb500e340>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25bb5012d90>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb51bcb80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25bb51c30d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x25bb51c9fd0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25bb521f1c0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb5241460>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x25bb522a400>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25bb5249940>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x25bb524e5e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x25bb524e880>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47fb5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    if i > 24 :\n",
    "        model.layers[i].trainable = True # dense layer\n",
    "    else :\n",
    "        model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f4f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce3a76ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False \t conv2d\n",
      "False \t batch_normalization\n",
      "False \t max_pooling2d\n",
      "False \t dropout\n",
      "False \t conv2d_1\n",
      "False \t batch_normalization_1\n",
      "False \t max_pooling2d_1\n",
      "False \t dropout_1\n",
      "False \t conv2d_2\n",
      "False \t batch_normalization_2\n",
      "False \t max_pooling2d_2\n",
      "False \t dropout_2\n",
      "False \t conv2d_3\n",
      "False \t batch_normalization_3\n",
      "False \t max_pooling2d_3\n",
      "False \t dropout_3\n",
      "False \t conv2d_4\n",
      "False \t batch_normalization_4\n",
      "False \t max_pooling2d_4\n",
      "False \t dropout_4\n",
      "False \t conv2d_5\n",
      "False \t batch_normalization_5\n",
      "False \t max_pooling2d_5\n",
      "False \t dropout_5\n",
      "False \t flatten\n",
      "True \t dropout_6\n",
      "True \t dense\n",
      "True \t dense_1\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.trainable, '\\t',layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41d2fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 109, 109, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 52, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "=================================================================\n",
      "Total params: 699,488\n",
      "Trainable params: 263,168\n",
      "Non-trainable params: 436,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fde9aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(len(labels),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39d5636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 109, 109, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 52, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 705,638\n",
      "Trainable params: 269,318\n",
      "Non-trainable params: 436,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89e38ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8986752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector_harcascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "detector_mtcnn = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c85f0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    pixels = np.asarray(img)\n",
    "#     results = detector_harcascade.detectMultiScale(img,1.2,4)\n",
    "    results = detector_mtcnn.detect_faces(pixels)\n",
    "    if len(results) > 0:\n",
    "        x1, y1, w, h = results[0]['box']\n",
    "#         x1,y1,w,h = results[0]\n",
    "        x1, y1 = abs(x1),abs(y1)\n",
    "        x2,y2 = x1 + w, y1 + h\n",
    "        img = pixels[y1:y2,x1:x2]\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img,(224,224))\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "def print_prog(val, val_len, folder, bar_size=20):\n",
    "    progr = \"=\"*round((val)*bar_size/val_len) + \" \"*round((val_len - (val))*bar_size/val_len)\n",
    "    if val == 0:\n",
    "        print(\"\", end=\"\\n\")\n",
    "    else:\n",
    "        print(\"[%s] (%d samples) \\t label : %s\\t\\t\" % (progr, val+1,folder), end=\"\\r\")\n",
    "\n",
    "\n",
    "# if use augmentasi image but is large for memory\n",
    "# def img_augmentasi(img):\n",
    "#     h,w = img.shape[:2]\n",
    "#     center = (w//2,h//2)\n",
    "    \n",
    "#     M_rot5 = cv2.getRotationMatrix2D(center,5,1.0)\n",
    "#     M_rot_neg_5 = cv2.getRotationMatrix2D(center,-5,1.0)\n",
    "#     M_rot_10 = cv2.getRotationMatrix2D(center,10,1.0)\n",
    "#     M_rot_neg_10 = cv2.getRotationMatrix2D(center,-10,1.0)\n",
    "#     M_trans_3=np.float32([[1,0,3], [0,1,0]])\n",
    "#     M_trans_neg_3=np.float32([[1,0,-3], [0,1,0]])\n",
    "#     M_trans_6=np.float32([[1,0,6], [0,1,0]])\n",
    "#     M_trans_neg_6=np.float32([[1,0,-6], [0,1,0]])\n",
    "#     M_trans_y3=np.float32([[1,0,0], [0,1,3]])\n",
    "#     M_trans_neg_y3=np.float32([[1,0,0], [0,1,-3]])\n",
    "#     M_trans_y6=np.float32([[1,0,0], [0,1,6]])\n",
    "#     M_trans_neg_y6=np.float32([[1,0,0], [0,1,-6]])\n",
    "    \n",
    "#     imgs=[]\n",
    "#     imgs.append(cv2.warpAffine(img, M_rot5,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_rot_neg_5,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_rot_10,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_rot_neg_10,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_3,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_neg_3,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_6,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_neg_6,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_y3,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_neg_y3,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_y6,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.warpAffine(img, M_trans_neg_y6,(w,h),borderValue=(255,255,255)))\n",
    "#     imgs.append(cv2.add(img, 10))\n",
    "#     imgs.append(cv2.add(img, 30))\n",
    "#     imgs.append(cv2.add(img, -10))\n",
    "#     imgs.append(cv2.add(img, -30))\n",
    "#     imgs.append(cv2.add(img, 15))\n",
    "#     imgs.append(cv2.add(img, 45))\n",
    "#     imgs.append(cv2.add(img, -15))\n",
    "#     imgs.append(cv2.add(img, -45))\n",
    "    \n",
    "    \n",
    "#     return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae3d1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025BB69A0DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[====================] (50 samples) \t label : .Uknown\t\t\n",
      "[====================] (50 samples) \t label : Azizi N\t\t\n",
      "[====================] (50 samples) \t label : Bhara M\t\t\n",
      "[====================] (50 samples) \t label : Cristiano Ronaldo\t\t\n",
      "[====================] (50 samples) \t label : Tony_Blair\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "data_sets = \"Datasets10/face_inputs/\"\n",
    "\n",
    "names = []\n",
    "images = []\n",
    "\n",
    "\n",
    "for folder in os.listdir(data_sets):\n",
    "    files = os.listdir(os.path.join(data_sets,folder))[:50]\n",
    "    for i, name in enumerate(files):\n",
    "        if (name.find(\".jpg\") > -1) or (name.find(\".JPG\") > -1):\n",
    "            img = cv2.imread(os.path.join(data_sets + folder ,name))\n",
    "            img = detect_face(img)\n",
    "            if img is not None :\n",
    "                images.append(img)\n",
    "                names.append(folder)\n",
    "                \n",
    "                print_prog(i,len(files), folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b46e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use augmentasi data\n",
    "# augmentasi_img = []\n",
    "# augmentasi_names = []\n",
    "# for i, img in enumerate(images):\n",
    "#     try:\n",
    "#         augmentasi_img.extend(img_augmentasi(img))\n",
    "#         augmentasi_names.extend([names[i]] * 20)\n",
    "#     except:\n",
    "#         print(i)\n",
    "\n",
    "\n",
    "# images.extend(augmentasi_img)\n",
    "# names.extend(augmentasi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de33f222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5880, 5880)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names),len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2bfd831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.Uknown', 1029)\n",
      "('Azizi N', 1050)\n",
      "('Bhara M', 1008)\n",
      "('Cristiano Ronaldo', 924)\n",
      "('Lionel Messi', 903)\n",
      "('Tony_Blair', 966)\n"
     ]
    }
   ],
   "source": [
    "unique , counts = np.unique(names,return_counts= True)\n",
    "for item in zip(unique,counts):\n",
    "    \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6f1073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(names)\n",
    "\n",
    "labels = le.classes_\n",
    "\n",
    "name_vec = le.transform(names)\n",
    "\n",
    "categorical_name_vec = to_categorical(name_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af6d46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8e62507",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(images, dtype=np.float32),   # input data\n",
    "                                                    np.array(categorical_name_vec),       # target/output data \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca5613f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4998, 224, 224) (4998, 6) (882, 224, 224) (882, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfc765e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af08284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.6136 - accuracy: 0.7599 - val_loss: 2.2924 - val_accuracy: 0.4660\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.5806 - accuracy: 0.7739 - val_loss: 2.5818 - val_accuracy: 0.4530\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.5821 - accuracy: 0.7719 - val_loss: 2.5751 - val_accuracy: 0.4540\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.5689 - accuracy: 0.7784 - val_loss: 2.3986 - val_accuracy: 0.4590\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.5764 - accuracy: 0.7711 - val_loss: 2.3725 - val_accuracy: 0.4640\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.5555 - accuracy: 0.7784 - val_loss: 2.2487 - val_accuracy: 0.4770\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.5707 - accuracy: 0.7721 - val_loss: 2.4999 - val_accuracy: 0.4590\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.5535 - accuracy: 0.7821 - val_loss: 2.6600 - val_accuracy: 0.4550\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.5427 - accuracy: 0.7836 - val_loss: 2.5584 - val_accuracy: 0.4430\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.5374 - accuracy: 0.7959 - val_loss: 2.5637 - val_accuracy: 0.4560\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 16\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    \n",
    "                    \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    validation_split=0.2   # 15% of train dataset will be used as validation set\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_batch_face\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
