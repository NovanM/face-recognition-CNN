{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b34a75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b2ffb",
   "metadata": {},
   "source": [
    "# Crop photo with detector harcascade or mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4750b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_harcascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e5d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    pixels = np.asarray(img)\n",
    "    results = detector_harcascade.detectMultiScale(img,1.2,4)\n",
    "    if len(results) > 0:\n",
    "        x1,y1,w,h = results[0]\n",
    "        \n",
    "        x1, y1 = abs(x1),abs(y1)\n",
    "        x2,y2 = x1 + w, y1 + h\n",
    "        img = pixels[y1:y2,x1:x2]\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img,(224,224))\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "def print_prog(val, val_len, folder, bar_size=20):\n",
    "    progr = \"=\"*round((val)*bar_size/val_len) + \" \"*round((val_len - (val))*bar_size/val_len)\n",
    "    if val == 0:\n",
    "        print(\"\", end=\"\\n\")\n",
    "    else:\n",
    "        print(\"[%s] (%d samples) \\t label : %s\\t\\t\" % (progr, val+1,folder), end=\"\\r\")\n",
    "\n",
    "def img_augmentasi(img):\n",
    "    h,w = img.shape[:2]\n",
    "    center = (w//2,h//2)\n",
    "    \n",
    "    M_rot5 = cv2.getRotationMatrix2D(center,5,1.0)\n",
    "    M_rot_neg_5 = cv2.getRotationMatrix2D(center,-5,1.0)\n",
    "    M_rot_10 = cv2.getRotationMatrix2D(center,10,1.0)\n",
    "    M_rot_neg_10 = cv2.getRotationMatrix2D(center,-10,1.0)\n",
    "    M_trans_3=np.float32([[1,0,3], [0,1,0]])\n",
    "    M_trans_neg_3=np.float32([[1,0,-3], [0,1,0]])\n",
    "    M_trans_6=np.float32([[1,0,6], [0,1,0]])\n",
    "    M_trans_neg_6=np.float32([[1,0,-6], [0,1,0]])\n",
    "    M_trans_y3=np.float32([[1,0,0], [0,1,3]])\n",
    "    M_trans_neg_y3=np.float32([[1,0,0], [0,1,-3]])\n",
    "    M_trans_y6=np.float32([[1,0,0], [0,1,6]])\n",
    "    M_trans_neg_y6=np.float32([[1,0,0], [0,1,-6]])\n",
    "    \n",
    "    imgs=[]\n",
    "    imgs.append(cv2.warpAffine(img, M_rot5,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_rot_neg_5,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_rot_10,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_rot_neg_10,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_3,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_neg_3,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_6,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_neg_6,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_y3,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_neg_y3,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_y6,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.warpAffine(img, M_trans_neg_y6,(w,h),borderValue=(255,255,255)))\n",
    "    imgs.append(cv2.add(img, 10))\n",
    "    imgs.append(cv2.add(img, 30))\n",
    "    imgs.append(cv2.add(img, -10))\n",
    "    imgs.append(cv2.add(img, -30))\n",
    "    imgs.append(cv2.add(img, 15))\n",
    "    imgs.append(cv2.add(img, 45))\n",
    "    imgs.append(cv2.add(img, -15))\n",
    "    imgs.append(cv2.add(img, -45))\n",
    "    \n",
    "    \n",
    "    return imgs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cdad8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] (50 samples) \t label : .Uknown\t\t\n",
      "[=================   ] (43 samples) \t label : Azizi N\t\t\n",
      "[====================] (50 samples) \t label : Bhara M\t\t\n",
      "[====================] (50 samples) \t label : Cristiano Ronaldo\t\t\n",
      "[====================] (50 samples) \t label : Tony_Blair\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "data_sets = \"Datasets10/train_new/\"\n",
    "\n",
    "names = []\n",
    "images = []\n",
    "\n",
    "\n",
    "for folder in os.listdir(data_sets):\n",
    "    files = os.listdir(os.path.join(data_sets,folder))[:50]\n",
    "    for i, name in enumerate(files):\n",
    "        if (name.find(\".jpg\") > -1) or (name.find(\".JPG\") > -1):\n",
    "            img = cv2.imread(os.path.join(data_sets + folder ,name))\n",
    "            img = detect_face(img)\n",
    "            if img is not None :\n",
    "                images.append(img)\n",
    "                names.append(folder)\n",
    "                \n",
    "                print_prog(i,len(files), folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec575688",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentasi_img = []\n",
    "augmentasi_names = []\n",
    "for i, img in enumerate(images):\n",
    "    try:\n",
    "        augmentasi_img.extend(img_augmentasi(img))\n",
    "        augmentasi_names.extend([names[i]] * 20)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "863acd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.extend(augmentasi_img)\n",
    "names.extend(augmentasi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "504b6964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4580, 4580)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmentasi_img), len(augmentasi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56a0caba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4809, 4809)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names), len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92fd3b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.Uknown', 1029)\n",
      "('Azizi N', 756)\n",
      "('Bhara M', 693)\n",
      "('Cristiano Ronaldo', 630)\n",
      "('Lionel Messi', 672)\n",
      "('Tony_Blair', 1029)\n"
     ]
    }
   ],
   "source": [
    "unique , counts = np.unique(names,return_counts= True)\n",
    "for item in zip(unique,counts):\n",
    "    \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5566aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(names)\n",
    "labels = le.classes_\n",
    "name_vec = le.transform(names)\n",
    "\n",
    "categorical_name_vec = tf.keras.utils.to_categorical(name_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e768aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class : 6\n",
      "['.Uknown' 'Azizi N' 'Bhara M' 'Cristiano Ronaldo' 'Lionel Messi'\n",
      " 'Tony_Blair']\n"
     ]
    }
   ],
   "source": [
    "print(\"number of class :\", len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59f601cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224) (4087, 6) (722, 224, 224) (722, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(np.array(images, dtype=np.float32),\n",
    "                                                np.array(categorical_name_vec),\n",
    "                                                test_size=0.15,random_state=42)\n",
    "print(x_train[0].shape, y_train.shape, x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e76b42df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4087, 224, 224, 1), (722, 224, 224, 1), (224, 224, 1))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
    "\n",
    "x_train.shape, x_test.shape, x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cd696e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 222, 222, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 222, 222, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 109, 109, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 52, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 421,638\n",
      "Trainable params: 420,774\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "     tf.keras.layers.Conv2D(16,(3,3), activation='relu', input_shape=(224,224,1)),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "     tf.keras.layers.MaxPooling2D(2,2),\n",
    "     tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "     tf.keras.layers.Conv2D(32,(3,3), activation='relu'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "     tf.keras.layers.MaxPooling2D(2,2),\n",
    "     tf.keras.layers.Dropout(0.3),\n",
    "     \n",
    "        \n",
    "     tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "     tf.keras.layers.MaxPooling2D(2,2),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "     \n",
    "        \n",
    "     tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "     tf.keras.layers.MaxPooling2D(2,2),\n",
    "     tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "     tf.keras.layers.Conv2D(256,(3,3), activation='relu'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "     tf.keras.layers.MaxPooling2D(2,2),\n",
    "     tf.keras.layers.Dropout(0.5),\n",
    "     \n",
    "     tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "     tf.keras.layers.MaxPooling2D(2,2),\n",
    "     tf.keras.layers.Dropout(0.5),    \n",
    "\n",
    "     tf.keras.layers.Flatten(),\n",
    "     tf.keras.layers.Dropout(0.5),\n",
    "     tf.keras.layers.Dense(1024, activation='relu'),\n",
    "\n",
    "     tf.keras.layers.Dense(len(labels),activation='softmax')                                   \n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c68fa89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80b81126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 1.7514 - accuracy: 0.3331 - val_loss: 2.9572 - val_accuracy: 0.1589\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 1.3262 - accuracy: 0.4818 - val_loss: 1.7050 - val_accuracy: 0.2286\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 100s 6s/step - loss: 1.1168 - accuracy: 0.5662 - val_loss: 1.5678 - val_accuracy: 0.2702\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.9210 - accuracy: 0.6222 - val_loss: 1.8189 - val_accuracy: 0.3227\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 100s 6s/step - loss: 0.8044 - accuracy: 0.6568 - val_loss: 2.0355 - val_accuracy: 0.3594\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.7058 - accuracy: 0.6895 - val_loss: 1.6637 - val_accuracy: 0.3692\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.6360 - accuracy: 0.7213 - val_loss: 2.7434 - val_accuracy: 0.3411\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.5462 - accuracy: 0.7574 - val_loss: 2.0391 - val_accuracy: 0.3191\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.4796 - accuracy: 0.7929 - val_loss: 2.3964 - val_accuracy: 0.3961\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.4243 - accuracy: 0.8253 - val_loss: 2.5920 - val_accuracy: 0.3301\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.3792 - accuracy: 0.8464 - val_loss: 4.7686 - val_accuracy: 0.2396\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.3327 - accuracy: 0.8639 - val_loss: 3.6298 - val_accuracy: 0.3643\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.3116 - accuracy: 0.8718 - val_loss: 5.7312 - val_accuracy: 0.1785\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.2434 - accuracy: 0.9006 - val_loss: 2.6734 - val_accuracy: 0.4988\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.2238 - accuracy: 0.9119 - val_loss: 6.0144 - val_accuracy: 0.3044\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.1914 - accuracy: 0.9223 - val_loss: 3.1956 - val_accuracy: 0.4560\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.1752 - accuracy: 0.9333 - val_loss: 4.7190 - val_accuracy: 0.3741\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.1423 - accuracy: 0.9480 - val_loss: 2.9333 - val_accuracy: 0.5012\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.1577 - accuracy: 0.9397 - val_loss: 0.3225 - val_accuracy: 0.8839\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.1491 - accuracy: 0.9474 - val_loss: 0.1398 - val_accuracy: 0.9572\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.1236 - accuracy: 0.9538 - val_loss: 0.3911 - val_accuracy: 0.8729\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.1081 - accuracy: 0.9615 - val_loss: 0.2513 - val_accuracy: 0.9181\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.1080 - accuracy: 0.9636 - val_loss: 0.2597 - val_accuracy: 0.9218\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.0854 - accuracy: 0.9676 - val_loss: 0.3803 - val_accuracy: 0.8802\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.0767 - accuracy: 0.9752 - val_loss: 0.8852 - val_accuracy: 0.7934\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.0704 - accuracy: 0.9731 - val_loss: 0.2630 - val_accuracy: 0.9156\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.0713 - accuracy: 0.9755 - val_loss: 0.7024 - val_accuracy: 0.8325\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.0682 - accuracy: 0.9761 - val_loss: 0.3471 - val_accuracy: 0.8973\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.0683 - accuracy: 0.9740 - val_loss: 0.2028 - val_accuracy: 0.9279\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 100s 6s/step - loss: 0.0517 - accuracy: 0.9816 - val_loss: 0.3138 - val_accuracy: 0.9108\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.0508 - accuracy: 0.9807 - val_loss: 0.1827 - val_accuracy: 0.9438\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.3152 - val_accuracy: 0.9254\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.0428 - accuracy: 0.9838 - val_loss: 0.2579 - val_accuracy: 0.9291\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 93s 6s/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 3.5259 - val_accuracy: 0.4719\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.0393 - accuracy: 0.9850 - val_loss: 0.7313 - val_accuracy: 0.8570\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 113s 7s/step - loss: 0.0478 - accuracy: 0.9835 - val_loss: 0.0606 - val_accuracy: 0.9841\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 0.4181 - val_accuracy: 0.8802\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.2147 - val_accuracy: 0.9523\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.0370 - accuracy: 0.9856 - val_loss: 0.1344 - val_accuracy: 0.9682\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 99s 6s/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.0778 - val_accuracy: 0.9817\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 100s 6s/step - loss: 0.0304 - accuracy: 0.9875 - val_loss: 0.4881 - val_accuracy: 0.8888\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.3769 - val_accuracy: 0.9120\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 0.7418 - val_accuracy: 0.8362\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 1.6090 - val_accuracy: 0.7408\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 3.8655 - val_accuracy: 0.5232\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0729 - val_accuracy: 0.9756\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.0541 - val_accuracy: 0.9829\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0117 - val_accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 99s 6s/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0150 - val_accuracy: 0.9951\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 99s 6s/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0548 - val_accuracy: 0.9829\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 50\n",
    "STEPS_PER_EPOCH = 16\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size= BATCH_SIZE,\n",
    "                    validation_split=0.2,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d583809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_batch_face.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "044bcbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x257a765f670>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x257a6296040>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x257a2e10c70>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a631ca30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x257a63b1be0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x257a63b1340>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x257a638dc70>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a638de50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x257a63c6f40>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x257a63c6400>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x257a6324190>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a6324c70>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x257a40456a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x257a4045190>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x257a4045280>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a4028b20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x257a4028a00>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x257a40284f0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x257a40285b0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a4028610>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x257a44984c0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x257a4498b50>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x257a44982e0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a44981c0>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x257a448f850>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x257a448f520>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x257a448f040>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x257a448fa00>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e6018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
